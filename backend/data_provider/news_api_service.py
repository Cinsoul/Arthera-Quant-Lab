"""
News APIé›†æˆæœåŠ¡
æä¾›å…¨çƒè´¢ç»æ–°é—»ã€å¸‚åœºèµ„è®¯æ•°æ®
"""

import aiohttp
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import logging

logger = logging.getLogger(__name__)

class NewsAPIService:
    """
    News APIæ•°æ®æœåŠ¡
    æä¾›ï¼šå…¨çƒæ–°é—»ã€è´¢ç»èµ„è®¯ã€ç‰¹å®šæ¥æºæ–°é—»
    """
    
    def __init__(self, api_key: str = None):
        if api_key is None:
            # ä»é…ç½®ç®¡ç†å™¨è·å–APIå¯†é’¥
            try:
                from .service_config_manager import get_service_config_manager
                config_manager = get_service_config_manager()
                self.api_key = config_manager.get_api_key('news_api')
            except Exception:
                self.api_key = None
        else:
            self.api_key = api_key
            
        self.base_url = "https://newsapi.org/v2"
        self.session = None
        
    async def get_session(self):
        """è·å–HTTPä¼šè¯"""
        if self.session is None:
            self.session = aiohttp.ClientSession()
        return self.session
    
    async def close(self):
        """å…³é—­ä¼šè¯"""
        if self.session:
            await self.session.close()
    
    async def _make_request(self, endpoint: str, params: Dict = None) -> Dict:
        """ç»Ÿä¸€APIè¯·æ±‚æ–¹æ³•"""
        try:
            session = await self.get_session()
            
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                'X-API-Key': self.api_key,
                'User-Agent': 'Arthera-Quant-Lab/1.0'
            }
            
            url = f"{self.base_url}/{endpoint}"
            
            async with session.get(url, params=params, headers=headers) as response:
                if response.status == 200:
                    data = await response.json()
                    return {"success": True, "data": data}
                elif response.status == 429:
                    return {"success": False, "error": "APIè¯·æ±‚é¢‘ç‡è¶…é™"}
                else:
                    error_text = await response.text()
                    return {"success": False, "error": f"HTTP {response.status}: {error_text}"}
                    
        except Exception as e:
            logger.error(f"News APIè¯·æ±‚å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    # ============================================================================
    # è´¢ç»æ–°é—»
    # ============================================================================
    
    async def get_financial_news(self, limit: int = 50) -> Dict[str, Any]:
        """è·å–è´¢ç»æ–°é—»"""
        try:
            # ä½¿ç”¨å•†ä¸šå¤´æ¡ä½œä¸ºè´¢ç»æ–°é—»
            result = await self.get_business_headlines(country="us", page_size=limit)
            
            if result.get("success"):
                articles = result.get("articles", [])
                
                # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                news_items = []
                for article in articles:
                    news_items.append({
                        "title": article.get("title", ""),
                        "content": article.get("description", ""),
                        "url": article.get("url", ""),
                        "publishedAt": article.get("publishedAt", ""),
                        "source": article.get("source", {}).get("name", "NewsAPI"),
                        "category": "business"
                    })
                
                return {
                    "success": True,
                    "news": news_items[:limit],
                    "total": len(news_items),
                    "source": "newsapi"
                }
            
            return {"success": False, "error": "æ— æ³•è·å–è´¢ç»æ–°é—»"}
            
        except Exception as e:
            logger.error(f"NewsAPIè´¢ç»æ–°é—»è·å–å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    async def get_business_headlines(self, country: str = "us", page_size: int = 50) -> Dict[str, Any]:
        """è·å–å•†ä¸šè´¢ç»å¤´æ¡æ–°é—»"""
        params = {
            "country": country,
            "category": "business",
            "pageSize": min(page_size, 100)  # APIé™åˆ¶æœ€å¤š100æ¡
        }
        
        result = await self._make_request("top-headlines", params)
        
        if result["success"] and result["data"]:
            news_data = result["data"]
            articles = news_data.get("articles", [])
            
            processed_news = []
            for article in articles:
                processed_news.append({
                    "source": article.get("source", {}).get("name"),
                    "author": article.get("author"),
                    "title": article.get("title"),
                    "description": article.get("description"),
                    "url": article.get("url"),
                    "url_to_image": article.get("urlToImage"),
                    "published_at": article.get("publishedAt"),
                    "content": article.get("content"),
                    "category": "business"
                })
            
            return {
                "success": True,
                "country": country,
                "category": "business",
                "total_results": news_data.get("totalResults", 0),
                "articles": processed_news,
                "source": "newsapi"
            }
        
        return result
    
    async def search_financial_news(self, query: str, days_back: int = 7, 
                                  page_size: int = 50) -> Dict[str, Any]:
        """æœç´¢è´¢ç»ç›¸å…³æ–°é—»"""
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        from_date = (datetime.now() - timedelta(days=days_back)).strftime("%Y-%m-%d")
        
        params = {
            "q": query,
            "searchIn": "title,description",
            "from": from_date,
            "sortBy": "publishedAt",
            "pageSize": min(page_size, 100),
            "language": "en"
        }
        
        result = await self._make_request("everything", params)
        
        if result["success"] and result["data"]:
            news_data = result["data"]
            articles = news_data.get("articles", [])
            
            processed_news = []
            for article in articles:
                processed_news.append({
                    "source": article.get("source", {}).get("name"),
                    "author": article.get("author"),
                    "title": article.get("title"),
                    "description": article.get("description"),
                    "url": article.get("url"),
                    "url_to_image": article.get("urlToImage"),
                    "published_at": article.get("publishedAt"),
                    "content": article.get("content"),
                    "relevance_score": self._calculate_relevance(article, query)
                })
            
            # æŒ‰ç›¸å…³æ€§æ’åº
            processed_news.sort(key=lambda x: x["relevance_score"], reverse=True)
            
            return {
                "success": True,
                "query": query,
                "date_range": f"{days_back} days",
                "total_results": news_data.get("totalResults", 0),
                "articles": processed_news,
                "source": "newsapi"
            }
        
        return result
    
    async def get_financial_sources_news(self, sources: List[str], 
                                       page_size: int = 50) -> Dict[str, Any]:
        """è·å–ç‰¹å®šè´¢ç»åª’ä½“çš„æ–°é—»"""
        # é»˜è®¤è´¢ç»åª’ä½“æº
        if not sources:
            sources = [
                "bloomberg", "reuters", "cnbc", "the-wall-street-journal",
                "financial-times", "fortune", "business-insider"
            ]
        
        sources_str = ",".join(sources)
        
        params = {
            "sources": sources_str,
            "sortBy": "publishedAt",
            "pageSize": min(page_size, 100)
        }
        
        result = await self._make_request("everything", params)
        
        if result["success"] and result["data"]:
            news_data = result["data"]
            articles = news_data.get("articles", [])
            
            processed_news = []
            for article in articles:
                processed_news.append({
                    "source": article.get("source", {}).get("name"),
                    "author": article.get("author"),
                    "title": article.get("title"),
                    "description": article.get("description"),
                    "url": article.get("url"),
                    "url_to_image": article.get("urlToImage"),
                    "published_at": article.get("publishedAt"),
                    "content": article.get("content"),
                    "category": "financial"
                })
            
            return {
                "success": True,
                "sources": sources,
                "total_results": news_data.get("totalResults", 0),
                "articles": processed_news,
                "source": "newsapi"
            }
        
        return result

    # ============================================================================
    # è‚¡ç¥¨ç›¸å…³æ–°é—»
    # ============================================================================
    
    async def get_stock_news(self, symbol: str, days_back: int = 7, 
                           page_size: int = 30) -> Dict[str, Any]:
        """è·å–ç‰¹å®šè‚¡ç¥¨ç›¸å…³æ–°é—»"""
        # æ„å»ºæœç´¢æŸ¥è¯¢
        queries = [
            f'"{symbol}"',  # ç²¾ç¡®åŒ¹é…è‚¡ç¥¨ä»£ç 
            f"{symbol} stock",  # è‚¡ç¥¨ç›¸å…³
            f"{symbol} earnings",  # è´¢æŠ¥ç›¸å…³
            f"{symbol} price"  # ä»·æ ¼ç›¸å…³
        ]
        
        all_articles = []
        
        for query in queries:
            result = await self.search_financial_news(query, days_back, page_size // len(queries))
            if result.get("success") and result.get("articles"):
                all_articles.extend(result["articles"])
        
        # å»é‡ï¼ˆåŸºäºURLï¼‰
        seen_urls = set()
        unique_articles = []
        for article in all_articles:
            url = article.get("url")
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_articles.append(article)
        
        # æŒ‰å‘å¸ƒæ—¶é—´æ’åº
        unique_articles.sort(key=lambda x: x.get("published_at", ""), reverse=True)
        
        return {
            "success": True,
            "symbol": symbol,
            "date_range": f"{days_back} days",
            "total_results": len(unique_articles),
            "articles": unique_articles[:page_size],
            "source": "newsapi"
        }
    
    async def get_crypto_news(self, crypto_symbol: str = "bitcoin", 
                            days_back: int = 7, page_size: int = 30) -> Dict[str, Any]:
        """è·å–åŠ å¯†è´§å¸ç›¸å…³æ–°é—»"""
        # åŠ å¯†è´§å¸ç›¸å…³æŸ¥è¯¢
        crypto_queries = [
            crypto_symbol,
            f"{crypto_symbol} price",
            f"{crypto_symbol} crypto",
            f"{crypto_symbol} cryptocurrency"
        ]
        
        all_articles = []
        
        for query in crypto_queries:
            result = await self.search_financial_news(query, days_back, page_size // len(crypto_queries))
            if result.get("success") and result.get("articles"):
                all_articles.extend(result["articles"])
        
        # å»é‡å’Œæ’åº
        seen_urls = set()
        unique_articles = []
        for article in all_articles:
            url = article.get("url")
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_articles.append(article)
        
        unique_articles.sort(key=lambda x: x.get("published_at", ""), reverse=True)
        
        return {
            "success": True,
            "crypto_symbol": crypto_symbol,
            "date_range": f"{days_back} days",
            "total_results": len(unique_articles),
            "articles": unique_articles[:page_size],
            "source": "newsapi"
        }

    # ============================================================================
    # å¸‚åœºæƒ…ç»ªåˆ†æ
    # ============================================================================
    
    async def get_market_sentiment_news(self, days_back: int = 3, 
                                      page_size: int = 50) -> Dict[str, Any]:
        """è·å–å¸‚åœºæƒ…ç»ªç›¸å…³æ–°é—»"""
        sentiment_keywords = [
            "market crash", "market rally", "bull market", "bear market",
            "recession", "economic growth", "inflation", "fed rate",
            "market volatility", "investor sentiment"
        ]
        
        all_articles = []
        
        for keyword in sentiment_keywords[:5]:  # é™åˆ¶æŸ¥è¯¢æ•°é‡
            result = await self.search_financial_news(keyword, days_back, 10)
            if result.get("success") and result.get("articles"):
                all_articles.extend(result["articles"])
        
        # å»é‡å’Œæƒ…ç»ªåˆ†æ
        seen_urls = set()
        analyzed_articles = []
        
        for article in all_articles:
            url = article.get("url")
            if url and url not in seen_urls:
                seen_urls.add(url)
                
                # ç®€å•æƒ…ç»ªåˆ†æ
                sentiment = self._analyze_sentiment(article)
                article["sentiment"] = sentiment
                analyzed_articles.append(article)
        
        # æŒ‰æƒ…ç»ªåˆ†æ•°æ’åº
        analyzed_articles.sort(key=lambda x: abs(x.get("sentiment", {}).get("score", 0)), reverse=True)
        
        return {
            "success": True,
            "analysis_period": f"{days_back} days",
            "total_results": len(analyzed_articles),
            "articles": analyzed_articles[:page_size],
            "sentiment_summary": self._calculate_sentiment_summary(analyzed_articles),
            "source": "newsapi"
        }

    # ============================================================================
    # å·¥å…·æ–¹æ³•
    # ============================================================================
    
    def _calculate_relevance(self, article: Dict, query: str) -> float:
        """è®¡ç®—æ–°é—»ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§åˆ†æ•°"""
        score = 0
        query_lower = query.lower()
        
        title = article.get("title", "").lower()
        description = article.get("description", "").lower()
        
        # æ ‡é¢˜åŒ¹é…æƒé‡æ›´é«˜
        if query_lower in title:
            score += 2
        
        # æè¿°åŒ¹é…
        if query_lower in description:
            score += 1
        
        # æ¥æºå¯ä¿¡åº¦
        source_name = article.get("source", {}).get("name", "").lower()
        trusted_sources = ["bloomberg", "reuters", "cnbc", "wsj", "financial times"]
        if any(trusted in source_name for trusted in trusted_sources):
            score += 0.5
        
        return score
    
    def _analyze_sentiment(self, article: Dict) -> Dict[str, Any]:
        """ç®€å•çš„æ–°é—»æƒ…ç»ªåˆ†æ"""
        text = f"{article.get('title', '')} {article.get('description', '')}".lower()
        
        # æ­£é¢è¯æ±‡
        positive_words = [
            "growth", "profit", "gain", "up", "rise", "increase", "bull", 
            "optimistic", "positive", "strong", "rally", "boom"
        ]
        
        # è´Ÿé¢è¯æ±‡  
        negative_words = [
            "crash", "fall", "decline", "loss", "down", "bear", "recession",
            "pessimistic", "negative", "weak", "drop", "collapse"
        ]
        
        positive_score = sum(1 for word in positive_words if word in text)
        negative_score = sum(1 for word in negative_words if word in text)
        
        # è®¡ç®—æƒ…ç»ªåˆ†æ•° (-1 to 1)
        total_score = positive_score + negative_score
        if total_score > 0:
            sentiment_score = (positive_score - negative_score) / total_score
        else:
            sentiment_score = 0
        
        # ç¡®å®šæƒ…ç»ªç±»åˆ«
        if sentiment_score > 0.2:
            sentiment_label = "positive"
        elif sentiment_score < -0.2:
            sentiment_label = "negative"
        else:
            sentiment_label = "neutral"
        
        return {
            "label": sentiment_label,
            "score": round(sentiment_score, 3),
            "positive_signals": positive_score,
            "negative_signals": negative_score
        }
    
    def _calculate_sentiment_summary(self, articles: List[Dict]) -> Dict[str, Any]:
        """è®¡ç®—æ–°é—»æ•´ä½“æƒ…ç»ªæ‘˜è¦"""
        if not articles:
            return {"overall": "neutral", "distribution": {}}
        
        sentiments = [article.get("sentiment", {}) for article in articles]
        labels = [s.get("label", "neutral") for s in sentiments]
        scores = [s.get("score", 0) for s in sentiments]
        
        # æƒ…ç»ªåˆ†å¸ƒ
        distribution = {
            "positive": labels.count("positive"),
            "negative": labels.count("negative"), 
            "neutral": labels.count("neutral")
        }
        
        # æ€»ä½“æƒ…ç»ª
        avg_score = sum(scores) / len(scores) if scores else 0
        
        if avg_score > 0.1:
            overall = "positive"
        elif avg_score < -0.1:
            overall = "negative"
        else:
            overall = "neutral"
        
        return {
            "overall": overall,
            "average_score": round(avg_score, 3),
            "distribution": distribution,
            "total_articles": len(articles)
        }

# åˆ›å»ºå…¨å±€News APIæœåŠ¡å®ä¾‹
news_api_service = None

def get_news_api_service() -> NewsAPIService:
    """è·å–News APIæœåŠ¡å®ä¾‹"""
    global news_api_service
    if news_api_service is None:
        news_api_service = NewsAPIService()
    return news_api_service

async def close_news_api_service():
    """å…³é—­News APIæœåŠ¡"""
    global news_api_service
    if news_api_service:
        await news_api_service.close()
        news_api_service = None

# æµ‹è¯•å‡½æ•°
async def test_news_api_service():
    """æµ‹è¯•News APIæœåŠ¡"""
    service = get_news_api_service()
    
    print("ğŸ§ª æµ‹è¯•News APIæœåŠ¡...")
    
    # æµ‹è¯•å•†ä¸šå¤´æ¡
    print("\n1. æµ‹è¯•å•†ä¸šå¤´æ¡...")
    headlines_result = await service.get_business_headlines("us", 5)
    print(f"ç»“æœ: {headlines_result.get('success', False)}")
    if headlines_result.get('success'):
        print(f"å¤´æ¡æ•°é‡: {len(headlines_result.get('articles', []))}")
    
    # æµ‹è¯•è‚¡ç¥¨æ–°é—»
    print("\n2. æµ‹è¯•è‚¡ç¥¨æ–°é—» (AAPL)...")
    stock_news_result = await service.get_stock_news("AAPL", 3, 5)
    print(f"ç»“æœ: {stock_news_result.get('success', False)}")
    if stock_news_result.get('success'):
        print(f"AAPLæ–°é—»æ•°é‡: {len(stock_news_result.get('articles', []))}")
    
    # æµ‹è¯•åŠ å¯†è´§å¸æ–°é—»
    print("\n3. æµ‹è¯•åŠ å¯†è´§å¸æ–°é—»...")
    crypto_news_result = await service.get_crypto_news("bitcoin", 3, 5)
    print(f"ç»“æœ: {crypto_news_result.get('success', False)}")
    
    # æµ‹è¯•å¸‚åœºæƒ…ç»ª
    print("\n4. æµ‹è¯•å¸‚åœºæƒ…ç»ªåˆ†æ...")
    sentiment_result = await service.get_market_sentiment_news(2, 10)
    print(f"ç»“æœ: {sentiment_result.get('success', False)}")
    if sentiment_result.get('success'):
        summary = sentiment_result.get('sentiment_summary', {})
        print(f"æ•´ä½“æƒ…ç»ª: {summary.get('overall', 'unknown')}")
    
    await service.close()
    print("\nâœ… News APIæµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(test_news_api_service())